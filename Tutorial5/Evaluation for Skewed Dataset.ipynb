{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e64a63a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation for Skewed Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea1e5d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "**CS5483 Data Warehousing and Data Mining**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e85dc",
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import weka.core.jvm as jvm\n",
    "import weka.plot.classifiers as plcls\n",
    "from weka.classifiers import Classifier, Evaluation\n",
    "from weka.core.classes import Random\n",
    "from weka.core.converters import Loader\n",
    "\n",
    "%matplotlib widget\n",
    "jvm.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a41eb58",
   "metadata": {},
   "source": [
    "## Class imbalance problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc451546",
   "metadata": {},
   "source": [
    "In this notebook, we will analyze a skewed dataset for detecting microcalcifications in mammograms. The goal is to build a classifier to identify whether a bright spot in a mammogram is a micro-calcification (an early sign of breast cancer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea14a2b1",
   "metadata": {},
   "source": [
    "<a title=\"Bakerstmd, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Mammo_breast_cancer_wArrows.jpg\"><img width=\"70%\" alt=\"Mammo breast cancer wArrows\" src=\"https://upload.wikimedia.org/wikipedia/commons/e/e7/Mammo_breast_cancer_wArrows.jpg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ea743",
   "metadata": {},
   "source": [
    "The dataset can be downloaded from\n",
    "[OpenML](https://www.openml.org/d/310) in [ARFF format](https://www.openml.org/data/download/52214/phpn1jVwe). The following loads the data using `python-weka-wrapper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47deb08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
    "data = loader.load_url(\"https://www.openml.org/data/download/52214/phpn1jVwe\")\n",
    "data.class_is_last()\n",
    "print(data.summary(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85621d",
   "metadata": {},
   "source": [
    "There are 7 attributes and over 11 thousand instances. To understand the dataset, refer to Section 4 of the original paper:\n",
    "\n",
    "- Woods, Kevin S., et al. \"Comparative evaluation of pattern recognition techniques for detection of microcalcifications.\" Biomedical Image Processing and Biomedical Visualization. Vol. 1905. International Society for Optics and Photonics, 1993. [(Available via CityU VPN.)](https://www.worldscientific.com/doi/abs/10.1142/9789812797834_0011)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68f3be",
   "metadata": {},
   "source": [
    "A set of 24 mammograms were segmented to locate small bright spots, which are the candidates for the classification of malignant clusters of micro-calcifications. The classification problem is based on the following attributes of the image segments:\n",
    "\n",
    "- Area (number of pixels)\n",
    "- Average grey level\n",
    "- Gradient strength (of perimeter pixels)\n",
    "- Root mean square noise (fluctuation of the pixel values)\n",
    "- Root mean square noise of local background\n",
    "- Contrast (average grey level minus average of a 2-pixel wide border)\n",
    "- (Low order moment-based) Shape descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d91e8",
   "metadata": {},
   "source": [
    "To compute the 10-fold cross-validation accuracy for `J48`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfafe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier(classname=\"weka.classifiers.trees.J48\")\n",
    "evl = Evaluation(data)\n",
    "evl.crossvalidate_model(clf, data, 10, Random(1))\n",
    "\n",
    "print(f\"Accuracy: {evl.percent_correct:.3g}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4285ec",
   "metadata": {},
   "source": [
    "You should see that the accuracy is close to 100%. To show the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f4f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix = pd.DataFrame(\n",
    "    evl.confusion_matrix,\n",
    "    dtype=int,\n",
    "    columns=[f'predicted class \"{v}\"' for v in data.class_attribute.values],\n",
    "    index=[f'class \"{v}\"' for v in data.class_attribute.values],\n",
    ")\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621d1785",
   "metadata": {},
   "source": [
    "Each row of the confusion matrix corresponds to a class value (1: malignant, -1: benign), and each column corresponds to a predicted class. Each entry is a count of instances belonging to a specific class and having a particular predicted class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce2b183",
   "metadata": {},
   "source": [
    "**Exercise** Assign to `percent_of_malignant_detected` the percentage of instances of class 1 predicted as class 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec89f1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffb761aa1a3490aee3eb44b083556758",
     "grade": false,
     "grade_id": "malignant-detected",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your python code here\n",
    "# end of python code\n",
    "\n",
    "print(f\"Percentage of malignant detected: {percent_of_malignant_detected:.3g}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5f8fd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a13f239583b0d82df4093221c23d1d3b",
     "grade": true,
     "grade_id": "test-malignant-detected",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85627ad",
   "metadata": {},
   "source": [
    "## Different Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b619d8",
   "metadata": {},
   "source": [
    "For a skewed dataset, one can achieve very high accuracy even by `ZeroR`, i.e., also predicting the class as the majority class regardless of the values of the input features. \n",
    "We must use other performance metrics to train and evaluate a classification algorithm properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a6087",
   "metadata": {},
   "source": [
    "````{admonition} Definition \n",
    "\n",
    "These metrics can be computed from the numbers of true/false positives/negatives:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{precision} &= \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\\\\ \n",
    "\\text{recall} &= \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\\\\ \n",
    "\\text{specificity} &= \\frac{\\text{TN}}{\\text{TN} + \\text{FP}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfeb534",
   "metadata": {},
   "source": [
    "To show the above metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c5cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_class = 1  # specify the postive class value\n",
    "performance = {\n",
    "    \"precision\": evl.precision(pos_class),\n",
    "    \"recall\": evl.recall(pos_class),\n",
    "    \"specificity\": evl.true_negative_rate(pos_class),\n",
    "}\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d369e2",
   "metadata": {},
   "source": [
    "Although specificity is close to 100%, precision and recall are below 80% and 60% respectively:\n",
    "\n",
    "- If a bright spot is classified as malignant, the chance it is malignant is less than 80%.\n",
    "- Out of all malignant bright spots, less than 60% are identified as malignant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5725923",
   "metadata": {},
   "source": [
    "The reason why close to 100% benign bright spots are identified as benign \n",
    "\n",
    "- is mainly because most bright spots are benign, but\n",
    "- not because the classifier can distinguish malignant bright spots from benign ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = evl.num_true_positives(pos_class)\n",
    "FN = evl.num_false_negatives(pos_class)\n",
    "FP = evl.num_false_positives(pos_class)\n",
    "TN = evl.num_true_negatives(pos_class)\n",
    "\n",
    "assert np.isclose(performance[\"precision\"], TP / (TP + FP))\n",
    "assert np.isclose(performance[\"recall\"], TP / (TP + FN))\n",
    "assert np.isclose(performance[\"specificity\"], TN / (TN + FP))\n",
    "\n",
    "TFPN = pd.DataFrame(\n",
    "    [[TP, FN], [FP, TP]],\n",
    "    dtype=int,\n",
    "    columns=[\"predicted +ve\", \"predicted -ve\"],\n",
    "    index=[\"+ve\", \"-ve\"],\n",
    ")\n",
    "TFPN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dceeac5",
   "metadata": {},
   "source": [
    "The above table is not the same as a confusion matrix since a confusion matrix\n",
    "\n",
    "- does not specify a positive class, and\n",
    "- can have more than two rows/columns in multi-class classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ec9fb1",
   "metadata": {},
   "source": [
    "**Exercise** Modify `performance` to include the negative predictive value. You can add the value using\n",
    "```Python\n",
    "performance['NPV'] = ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14957201",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae7bc2c983f0bd84ab2d3603f445886a",
     "grade": false,
     "grade_id": "npv",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# your python code here\n",
    "# end of python code\n",
    "\n",
    "print(f\"negative predictive value (NPV): {performance['NPV']:.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec024f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "004fbec5b7b56fa027cba7caf9ca868e",
     "grade": true,
     "grade_id": "test-npv",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-output",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b69ceb",
   "metadata": {},
   "source": [
    "$F_{\\beta}$-score is another measure that captures the performance in both precision and recall:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881cf91c",
   "metadata": {},
   "source": [
    "````{admonition} Definition \n",
    "\n",
    "$F_{\\beta}$-score is defined as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "F_{\\beta} &:= \\left( \\frac{\\text{precision}^{-1} + \\beta^2 \\cdot \\text{recall}^{-1}}{\\beta^2 + 1}\\right)^{-1}\\\\\n",
    "&= \\frac{(\\beta^2+1)\\cdot \\text{precision}\\cdot \\text{recall} }{\\beta^2\\text{precision} + \\text{recall}}.\n",
    "\\end{align}\n",
    "$$ (F_beta)\n",
    "\n",
    "$F$-score is the special case when $\\beta=1$,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "F := F_1 &= \\left( \\frac{\\text{precision}^{-1} + \\text{recall}^{-1}}{2}\\right)^{-1} \\\\\n",
    "&= \\frac{2\\cdot \\text{precision}\\cdot \\text{recall} }{\\text{precision} + \\text{recall}},\n",
    "\\end{align}\n",
    "$$ (F)\n",
    "\n",
    "which is the harmonic mean of precision and recall. \n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb9ba7f",
   "metadata": {},
   "source": [
    "$F$-score is useful in training a classifier to maximize both precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580503ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance[\"F\"] = evl.f_measure(pos_class)\n",
    "print(f\"F-score: {performance['F']:.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed08d6",
   "metadata": {},
   "source": [
    "**Exercise** For the $F_{\\beta}$ score, we can increase $\\beta$ to put more weight on recall. Modify `performance` to include the $F_2$ score. You can set the value using\n",
    "\n",
    "```Python\n",
    "performance['F_2'] = ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f53b80",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4221e6722e398d0a1ba0a4ffb23cb2a7",
     "grade": false,
     "grade_id": "F2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# your python code here\n",
    "# end of python code\n",
    "\n",
    "print(f\"F_2 score: {performance['F_2']:.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f970b90",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c6847f2a0603d797cd9c588ed7f1072",
     "grade": true,
     "grade_id": "test-F2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8ba0d",
   "metadata": {},
   "source": [
    "**Exercise** Using `ZeroR` as the classifier, assign to `ZeroR_performance` a dictionary of precision, recall, and specificity. You can create the dictionary as follows:\n",
    "```Python\n",
    "ZeroR_performance = {\n",
    "    'precision': ___,\n",
    "    'recall': ___,\n",
    "    'specificity': ___\n",
    "}\n",
    "```\n",
    "\n",
    "Use 10-fold cross-validation with a random seed of `1`. If the value is not a number, you may enter it as `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de2c670",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af4560fca0f1a265476a69159cfeab1c",
     "grade": false,
     "grade_id": "ZeroR",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# your python code here\n",
    "# end of python code\n",
    "\n",
    "ZeroR_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06749bd7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94c5b6b5782353a6dd4606dc02f2a86f",
     "grade": true,
     "grade_id": "test-ZeroR",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# hidden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7faebf",
   "metadata": {},
   "source": [
    "**Exercise** Is ZeroR a good baseline classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cfce20",
   "metadata": {},
   "source": [
    "````{hint}\n",
    "\n",
    "Is the accuracy misleading? Can a random decision maker do better than zeroR?\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963fdbee",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4098962965ff36e2070f1b192c0f55a1",
     "grade": true,
     "grade_id": "baseline",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9777be",
   "metadata": {},
   "source": [
    "## Operating Curves for Probabilistic Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa543a7f",
   "metadata": {},
   "source": [
    "For a probabilistic classifier that returns probabilities of different classes, we can obtain a trade-off between precision and recall by changing a threshold $\\gamma$ for positive prediction, i.e., predict positive if and only if the probability estimate for positive class is larger than $\\gamma$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a34740",
   "metadata": {},
   "source": [
    "To plot the [precision-recall curve](https://waikato.github.io/weka-wiki/roc_curves/) and prints the area under the curve, we can use the following tool:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aedcac3",
   "metadata": {},
   "source": [
    "```python\n",
    "import weka.plot.classifiers as plcls\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dd633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plcls.plot_prc(evl, class_index=[1])\n",
    "performance[\"PRC\"] = evl.area_under_prc(pos_class)\n",
    "print(f\"area under precision-recall curve (PRC): {performance['PRC']:.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0abe10c",
   "metadata": {},
   "source": [
    "**Exercise** One can operate the classifier at any point on the curve by an appropriate choice of $\\gamma$. Is it a good idea to operate at the initial part of the curve where the slope is strictly positive?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eac222f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1121e1e3d949136048751933292e0b19",
     "grade": true,
     "grade_id": "PRC",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6b9a0",
   "metadata": {},
   "source": [
    "**Exercise** The above curve shows that the classifier can achieve 100% recall but not 100% precision. If you can choose any classifier, is it always possible to achieve 100% recall for any given data set? How about 100% precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b9a34",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "769f0f9cf0c70700047f4aad9b1c080f",
     "grade": true,
     "grade_id": "perfect-recall",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d52f6",
   "metadata": {},
   "source": [
    "We can also plot the ROC (receiver operator characteristics) curve to show the trade-off between recall (true positive rate) and false positive rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db62a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plcls.plot_roc(evl, class_index=[1])\n",
    "performance[\"AUC\"] = evl.area_under_roc(pos_class)\n",
    "print(f\"area under ROC curve (AUC): {performance['AUC']:.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa67c82d",
   "metadata": {},
   "source": [
    "**Exercise** The above curve shows that the classifier can achieve 0% false positive rate. If you can choose the classifier, is it always possible to achieve 0% false positive rate for any given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6be8b9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "198e1b2272cf95a2266274391282faed",
     "grade": true,
     "grade_id": "zero-false-positive",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
