{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c495625a",
   "metadata": {},
   "source": [
    "# Evaluation of Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2867a0",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "**CS5483 Data Warehousing and Data Mining**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d169f9",
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn import datasets, preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fda16c4",
   "metadata": {},
   "source": [
    "In this notebook, we will consider different methods of evaluating clustering solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca117244",
   "metadata": {},
   "source": [
    "## Intrinsic measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70243fc8",
   "metadata": {},
   "source": [
    "The intrinsic measures of cluster quality are helpful when the ground truth is unavailable or should not be used. For example, to determine the number of clusters, we can compare the intrinsic measures of the clustering solutions for different numbers of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494d865",
   "metadata": {},
   "source": [
    "### Elbow Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faff32e1",
   "metadata": {},
   "source": [
    "````{admonition} Definition \n",
    "\n",
    "To determine the number of clusters for a centroid-based clustering algorithm, the elbow method uses the within-cluster sum of squared errors\n",
    "\n",
    "$$\n",
    "{WSS}(k) := \\sum_{j\\in [k]} \\sum_{\\M{p}\\in C_j} \\operatorname{dist}(\\M{p},\\M{c}_j)^2,\n",
    "$$ (WSS)\n",
    "\n",
    "where $[k]$ denotes a set of positive integer $k$ unique indices,\n",
    "- $\\Set{C_j|1\\in [k]}$ is a clustering solution obtained by the centroid-based algorithm, and\n",
    "- $\\M{c}_j$ is the cluster center for $C_j$. \n",
    "\n",
    "Instead of minimizing $\\operatorname{WSS}(k)$ over $k$, it chooses $k$ where\n",
    "- $\\operatorname{WSS}(k)-\\operatorname{WSS}(k-1)$ is large, but\n",
    "- $\\operatorname{WSS}(k+1)-\\operatorname{WSS}(k)$ is small.\n",
    "\n",
    "Along the curve of $\\operatorname{WSS}(k)$ against $k$, the above choice is located at the 'elbow' of the curve.\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3aeb9",
   "metadata": {},
   "source": [
    "The following diagram shows the KnowledgeFlow interface of Weka that applies `SimpleKMeans` to the `iris.2D.arff` dataset for different choices of $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ebde92",
   "metadata": {},
   "source": [
    "![Elbow method](images/elbow.dio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf58aa",
   "metadata": {},
   "source": [
    "Implement the above using Weka."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f9fa1",
   "metadata": {},
   "source": [
    "**Exercise** Complete the following `DataFrame` `df_WSS` by recording $\\operatorname{WSS}(k)$ for $k$ from 1 to 4. Your answer may look like\n",
    "\n",
    "```python\n",
    "...\n",
    "df_WSS['WSS'] = [__, __, __, __]\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ebc9a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3874a1a2f84ca6889408cad3e6ea3e37",
     "grade": false,
     "grade_id": "elbow",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "df_WSS = pd.DataFrame(columns=[\"k\", \"WSS\"])\n",
    "df_WSS[\"k\"] = np.arange(1, 5, dtype=int)\n",
    "df_WSS[\"WSS\"] = df_WSS[\"WSS\"].astype(float)\n",
    "# your python code here\n",
    "# end of python code\n",
    "\n",
    "\n",
    "# plot WSS as a function of k\n",
    "df_WSS.plot(x=\"k\", y=\"WSS\", xlabel=r\"$k$\", ylabel=\"WSS\", legend=False)\n",
    "# plt.xlabel(\"k\")\n",
    "# plt.ylabel(\"WSS\")\n",
    "plt.show()\n",
    "df_WSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca633ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c6e4848996ac5e0834eb6b4f02c00ff",
     "grade": true,
     "grade_id": "test-elbow",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# hidden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487135a0",
   "metadata": {},
   "source": [
    "### Silhouette analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117285b5",
   "metadata": {},
   "source": [
    "An alternative method to the elbow method is to compute the silhouette coefficient below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd461a",
   "metadata": {},
   "source": [
    "````{admonition} Definition \n",
    "\n",
    "For each sample $\\M{p}\\in C\\in \\mc{P}$ where $\\mc{P}$ is a clustering solution that partitions the data set $D$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "s(\\M{p}) := \n",
    "\\begin{cases}\n",
    "\\text{undefined}, & \\abs{\\mc{P}}=0\\\\\n",
    "0, & \\abs{C}=1\\\\\n",
    "\\frac{b(\\M{p})-a(\\M{p})}{\\max\\Set{a(\\M{p}), b(\\M{p})}}, & \\text{otherwise,}\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "a(\\M{p}) &:= \\frac{1}{\\abs{C}} \\sum_{\\M{q}\\in C} \\operatorname{dist}(\\M{p},\\M{q}) && \\text{(mean intra-cluster distance)}\\\\\n",
    "b(\\M{p}) &:= \\min_{C'\\in \\mc{P}} \\sum_{\\M{q}\\in C'} \\operatorname{dist}(\\M{p},\\M{q}) && \\text{(mean nearest-cluster distance)}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b54520a",
   "metadata": {},
   "source": [
    "We will use the existing implementation in `sklearn`. First, import the iris dataset from `sklearn.datasets` and store it as a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fb1a82",
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# load the dataset from sklearn\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "# create a DataFrame to help further analysis\n",
    "df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "df[\"target\"] = dataset.target\n",
    "df.target = df.target.astype(\"category\")\n",
    "df.target = df.target.cat.rename_categories(dataset.target_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0184c242",
   "metadata": {},
   "source": [
    "To cluster the data using $k$-means clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe8049e",
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "kmeans_minmax_normalized = make_pipeline(\n",
    "    preprocessing.MinMaxScaler(), KMeans(n_clusters=3, random_state=0)\n",
    ")\n",
    "kmeans_minmax_normalized\n",
    "\n",
    "feature1, feature2 = \"petal length (cm)\", \"petal width (cm)\"\n",
    "labels = kmeans_minmax_normalized.fit_predict(df[[feature1, feature2]])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "_ = plt.subplot(121, title=\"Cluster assignment\", xlabel=feature1, ylabel=feature2)\n",
    "plt.scatter(df[feature1], df[feature2], c=labels)\n",
    "\n",
    "plt.subplot(122, title=\"Class (ground truth)\", xlabel=feature1, sharey=_)\n",
    "plt.scatter(df[feature1], df[feature2], c=dataset[\"target\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697762bd",
   "metadata": {},
   "source": [
    "**Exercise** Complete the following `DataFrame` `df_silouette` by recording the silhouette coefficients for different number $k$ of clusters from 2 to 10. You may enter your code as\n",
    "\n",
    "```python\n",
    "        ...\n",
    "        df_silouette.loc[i, 's'] = silhouette_score(___, ___)\n",
    "        ...\n",
    "```\n",
    "\n",
    "using the [`silhouette_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html) imported from\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import silhouette_score\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ca1d3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d8f714946a67e42ca4e379c75613fe1",
     "grade": false,
     "grade_id": "silhouette",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "df_silouette = pd.DataFrame(columns=[\"k\", \"s\"])\n",
    "df_silouette[\"k\"] = np.arange(2, 11, dtype=int)\n",
    "df_silouette[\"s\"] = df_silouette[\"s\"].astype(float)\n",
    "for i in range(len(df_silouette)):\n",
    "    labels_ = make_pipeline(\n",
    "        preprocessing.MinMaxScaler(),\n",
    "        KMeans(n_clusters=df_silouette.loc[i, \"k\"], random_state=0),\n",
    "    ).fit_predict(df[[feature1, feature2]])\n",
    "    # your python code here\n",
    "    # end of python code\n",
    "    \n",
    "\n",
    "# plot WSS as a function of k\n",
    "df_silouette.plot(x=\"k\", y=\"s\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"silouette score\")\n",
    "plt.show()\n",
    "df_silouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14d6b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57e8bc1388dd32db66ee4777d415f1f3",
     "grade": true,
     "grade_id": "test-silhouette",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# hidden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8002d740",
   "metadata": {},
   "source": [
    "```{seealso}\n",
    "In a more elaborate [silhouette analysis](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py), \n",
    "- we plot the silhouette coefficients for different clusters and points in each cluster,\n",
    "- and determine the number of clusters based on the variations in the silhouette coefficients and cluster sizes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877733f9",
   "metadata": {},
   "source": [
    "### Extrinsic measures of cluster quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f8c82a",
   "metadata": {},
   "source": [
    "Suppose $L(\\M{p})$ and $C(\\M{p})$ are the class and cluster labels of each sample $\\M{p}\\in D$. An extrinsic measure compares how similar the corresponding partitions $\\Set{L_i}$ and $\\Set{C_i}$ are, where\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L_i &:=\\Set{\\M{p}|L(\\M{p})=i}\\\\\n",
    "C_i &:=\\Set{\\M{p}|C(\\M{p})=i}.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189bbff",
   "metadata": {},
   "source": [
    "#### Pairwise correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afce728d",
   "metadata": {},
   "source": [
    "Define the indicator of correct clustering for a pair $\\M{p}, \\M{q}\\in D$ as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\operatorname{correctness}(\\M{p},\\M{q}) := \n",
    "\\begin{cases}\n",
    "1 & L(\\M{p})=L(\\M{q}) \\iff C(\\M{p})=C(\\M{q})\\\\\n",
    "0 & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$ (correctness)\n",
    "\n",
    "In other words, the clustering for the pair of samples is correct when \n",
    "- the samples have equal class labels and equal cluster labels, or\n",
    "- the samples have different class labels and different cluster labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78766522",
   "metadata": {},
   "source": [
    "The following function returns a boolean matrix of $[\\operatorname{correctness}(\\M{p},\\M{q})]$, with rows an columns indexed by $\\M{p}$ and $\\M{q}$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctness(class_labels, cluster_labels):\n",
    "    \"\"\"Returns the pairwise correctness matrix for the class and cluster labels.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    class_labels (array): non-negative integer class labels for certain samples\n",
    "    cluster_labels (array): corresponding non-negative integer cluster labels\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    A matrix (2D array) of correctness(p,q) with rows and columns indexed by\n",
    "    p and q, respectively, in the samples. correctness(p,q) indicates whether\n",
    "      - p and q have equal class labels and equal cluster labels, or\n",
    "      - p and q have different class labels and different cluster labels.\n",
    "    \"\"\"\n",
    "    class_labels = np.asarray(class_labels)\n",
    "    cluster_labels = np.asarray(cluster_labels)\n",
    "\n",
    "    eq_class = class_labels.reshape(-1, 1) == class_labels.reshape(1, -1)\n",
    "    eq_cluster = cluster_labels.reshape(-1, 1) == cluster_labels.reshape(1, -1)\n",
    "\n",
    "    return (eq_class & eq_cluster) | ~(eq_class | eq_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234cab2",
   "metadata": {},
   "source": [
    "For instance, consider the following class and cluster labels:\n",
    "\n",
    "|index $i$|class label $L(\\M{p}_i)$ | cluster label $C(\\M{p}_i)$|\n",
    "|:-:|:----------:|:----------:|\n",
    "| 0 | 0 | 1 |\n",
    "| 1 | 0 | 1 |\n",
    "| 2 | 1 | 0 |\n",
    "\n",
    "The correctness matrix and the fraction correctly clustered pairs are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctness_matrix = correctness(class_labels=[0, 0, 1], cluster_labels=[1, 1, 0])\n",
    "correctness_accuracy = correctness_matrix.mean()\n",
    "print(f\"Correctness matrix:\\n {correctness_matrix}\")\n",
    "print(f\"Accuracy: {correctness_matrix.mean():.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b1e16",
   "metadata": {},
   "source": [
    "**Exercise** Assign the accuracy to `correctness_accuracy` the accuracy for the $k$-means clustering solution on the iris dataset. Try to have as many samples as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c04ca",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40379b43b593e5b90ea204c13d92c6fb",
     "grade": false,
     "grade_id": "iris-correctness",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# your python code here\n",
    "# end of python code\n",
    "\n",
    "correctness_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee1c91",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "262612dfc77bb9e56ca4bdeb6033b585",
     "grade": true,
     "grade_id": "test-iris-correctness",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# hidden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc73c0f5",
   "metadata": {},
   "source": [
    "**Exercise** Give a choice of `class_labels` and `cluster_labels` that give the smallest possible accuracy computed using `correctness`. Assign the accuracy to `correctness_accuracy`. Try to have as many samples as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ae653",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "baedc2e80bf7857ad9fba08b0027b3e9",
     "grade": false,
     "grade_id": "correctness",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# your python code here\n",
    "# end of python code\n",
    "\n",
    "correctness_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65dad19",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10b763c92cf67e0291c889b6811b0a9c",
     "grade": true,
     "grade_id": "test-correctness",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# hidden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9277ac91",
   "metadata": {},
   "source": [
    "#### B-Cubed metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea70ce4",
   "metadata": {},
   "source": [
    "The accuracy computed from the pairwise correctness matrix can be misleading as it is dominated by true negatives. Similar to the class imbalance problem, precision and recall can be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705917f",
   "metadata": {},
   "source": [
    "````{admonition} Definition \n",
    "\n",
    "For every point $\\M{p}\\in D$, the B-Cubed precision and recall are defined respectively as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\operatorname{precision}(\\M{p}) &:= \\frac{\\abs{\\Set{\\M{q}\\in D|C(\\M{p})=C(\\M{q}), L(\\M{p})=L(\\M{q})}}}{\\abs{\\Set{\\M{q}\\in D|C(\\M{p})=C(\\M{q})}}}\\\\\n",
    "\\operatorname{recall}(\\M{p}) &:= \\frac{\\abs{\\Set{\\M{q}\\in D|C(\\M{p})=C(\\M{q}), L(\\M{p})=L(\\M{q})}}}{\\abs{\\Set{\\M{q}\\in D|L(\\M{p})=L(\\M{q})}}}.\n",
    "\\end{align}\n",
    "$$ (B-Cubed)\n",
    "\n",
    "The overall precision and recall are the average precisions and recalls of each point.\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e81b0a1",
   "metadata": {},
   "source": [
    "For instance, consider the following class and cluster labels:\n",
    "\n",
    "|index $i$|class label $L(\\M{p}_i)$ | cluster label $C(\\M{p}_i)$|\n",
    "|:-:|:----------:|:----------:|\n",
    "| 0 | 0 | 0 |\n",
    "| 1 | 0 | 1 |\n",
    "| 2 | 1 | 2 |\n",
    "| 3 | 1 | 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c7222c",
   "metadata": {},
   "source": [
    "The precision and recall for each point are\n",
    "\n",
    "|index $i$|precision for $\\M{p}_i$ | recall for $\\M{p}_i$|\n",
    "|:-:|:----------:|:----------:|\n",
    "| 0 | 1 | 0.5 |\n",
    "| 1 | 1 | 0.5 |\n",
    "| 2 | 1 | 1 |\n",
    "| 3 | 1 | 1 |\n",
    "\n",
    "and so the overall precision and recall are $1$ and $0.75$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b179804",
   "metadata": {},
   "source": [
    "**Exercise** Complete the following class that computes each sample's B-Cubed precision and recall and averages them over the samples. Your solution may look like this:\n",
    "```python\n",
    "        ...\n",
    "        FPs = (___ & ___).sum(axis=1)\n",
    "        FNs = (___ & ___).sum(axis=1)\n",
    "\n",
    "        self.precisions = TPs / (___ + ___)\n",
    "        self.recalls = ___\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee8b055",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10ee6e7f5d2ee91b55c81c05dec7e27d",
     "grade": false,
     "grade_id": "BCubed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "class BCubed:\n",
    "    \"\"\"Compute B-Cubed precision and recall.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    class_labels: int array\n",
    "        Non-negative integer class labels for certain samples.\n",
    "    cluster_labels: int array\n",
    "        Corresponding non-negative integer cluster labels.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    precisions: array of float\n",
    "        B-Cubed precisions for each sample.\n",
    "    recalls: array of float\n",
    "        B-Cubed recalls for each sample.\n",
    "    precision: float\n",
    "        Overall B-Cubed precision.\n",
    "    recall: float\n",
    "        Overall B-Cubed recall.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, class_labels, cluster_labels):\n",
    "        self.class_labels = np.asarray(class_labels)\n",
    "        self.cluster_labels = np.asarray(cluster_labels)\n",
    "\n",
    "        eq_class = self.class_labels[:, None] == self.class_labels[None, :]\n",
    "        eq_cluster = self.cluster_labels[:, None] == self.cluster_labels[None, :]\n",
    "\n",
    "        TPs = (eq_class & eq_cluster).sum(axis=1)\n",
    "        # your python code here\n",
    "        # end of python code\n",
    "        \n",
    "        self.precision = self.precisions.mean()\n",
    "        self.recall = self.recalls.mean()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Precision: {self.precision:.3g}\\n\" + f\"Recall: {self.recall:.3g}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca03291",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00cc30e4adad933a2d64ac33703a2965",
     "grade": true,
     "grade_id": "test-BCubed",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-output",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "# simple case\n",
    "bcubed_eval = BCubed(class_labels=[0, 0, 1, 1], cluster_labels=[0, 1, 2, 2])\n",
    "assert np.isclose(bcubed_eval.precisions, [1, 1, 1, 1], rtol=1e-3).all()\n",
    "assert np.isclose(bcubed_eval.recalls, [0.5, 0.5, 1, 1], rtol=1e-3).all()\n",
    "# test on iris\n",
    "bcubed_eval = BCubed(dataset[\"target\"], labels)\n",
    "print(bcubed_eval)\n",
    "assert np.isclose(bcubed_eval.precision, 0.9252136752136751, rtol=1e-3)\n",
    "assert np.isclose(bcubed_eval.recall, 0.9253333333333335, rtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cddcca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c0454fc9485d53f2aeb4ab3f437d028",
     "grade": true,
     "grade_id": "htest-BCubed",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# hidden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc7983",
   "metadata": {},
   "source": [
    "#### Classes to Clusters Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d2de1",
   "metadata": {},
   "source": [
    "Instead of using pairwise comparison, Weka uses the classes-to-clusters evaluation. The computation of accuracy can be cast as a linear sum assignment problem, also known as the maximum weight matching in bipartite graphs. More precisely:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e6174",
   "metadata": {},
   "source": [
    "````{admonition} Definition \n",
    "\n",
    "A classes-to-clusters assignment is a matching between the class and cluster labels. It can be represented by a boolean matrix $[\\delta_{ij}]$ for class label $i$ and cluster label $j$, where \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\delta_{ij} \n",
    "&= \\begin{cases}\n",
    "1 & \\text{if class $i$ is assigned to cluster $j$,}\\\\\n",
    "0 & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The accuracy for classes-to-clusters evaluation is then given by\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{accuracy} &= \n",
    "\\max_{[\\delta_{ij}]} \\sum_{i} \\sum_{j} \n",
    "\\overbrace{\\left|\\{\\M{p}\\in D|L(\\M{p})=i, C(\\M{p})=j\\}\\right|}^{n_{ij}:=} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $C(\\M{p})$ and $L(\\M{p})$ are the class and cluster labels, respectively, for the data point $\\M{p}\\in D$.\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b254f1b",
   "metadata": {},
   "source": [
    "It will be useful to compute a matrix of the counts $n_{ij}$ of samples with class label $i$ as row index and cluster label $j$ as column index. The following function implements such computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d8413",
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def class_cluster_counts(class_labels, cluster_labels):\n",
    "    \"\"\"Returns the class-cluster count matrix with rows and columns indexed by\n",
    "    class and cluster labels, respectively.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    class_labels (array): non-negative integer class labels for certain samples\n",
    "    cluster_labels (array): corresponding non-negative integer cluster labels\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    counts: a matrix of counts of samples with rows indexed by class labels and\n",
    "            columns index by cluster labels.\n",
    "    \"\"\"\n",
    "    counts = np.zeros((class_labels.max() + 1, cluster_labels.max() + 1), dtype=int)\n",
    "    for i, j in np.column_stack((class_labels, cluster_labels)):\n",
    "        counts[i, j] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71456ca6",
   "metadata": {},
   "source": [
    "For the $k$-means clustering on the iris dataset, the matrix $[n_{ij}]$ of class-cluster counts is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815340a4",
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "counts = class_cluster_counts(dataset[\"target\"], labels)\n",
    "df_counts = pd.DataFrame(counts)\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aa58fa",
   "metadata": {},
   "source": [
    "We can use [`linear_sum_assignment`][lsa] from `scipy.optimize` module to find the optimal assignment as follows:\n",
    "\n",
    "```python\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "```\n",
    "\n",
    "[lsa]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linear_sum_assignment.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8efa0d",
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "classes, clusters = linear_sum_assignment(counts, maximize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28399648",
   "metadata": {},
   "source": [
    "The following highlights the optimal assignment on the class-cluster count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543df644",
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def highlight(data):\n",
    "    attr = \"background-color: yellow\"\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            [attr if i == j else \"\" for j in range(len(data.columns))]\n",
    "            for i in range(len(data.index))\n",
    "        ],\n",
    "        index=data.index,\n",
    "        columns=data.columns,\n",
    "    )\n",
    "\n",
    "\n",
    "df_counts.style.apply(highlight, axis=None, subset=(classes, clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae37449",
   "metadata": {},
   "source": [
    "**Exercise** Complete the following class that implements the classes-to-cluster evaluation using `linear_sum_assignment` from `scipy.optimize` module. Your solution may look like this:\n",
    "```python\n",
    "        ...\n",
    "        # counts of samples indexed by class labels followed by cluster labels\n",
    "        counts = class_cluster_counts(____, ____)\n",
    "        \n",
    "        # compute the best assignment of class labels to cluster labels\n",
    "        # that maximizes accuracy        \n",
    "        self.classes, self.clusters = linear_sum_assignment(_____, maximize=____)\n",
    "        self.accuracy = float(counts[____, ____].sum()) / counts.sum()\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c442a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75db7ab421da343144e1bbd0f7cc2a63",
     "grade": false,
     "grade_id": "c2c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "class Classes2ClustersEvaluation:\n",
    "    \"\"\"Classes-to-clusters evaluation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    class_labels: array\n",
    "        Non-negative integer class labels for certain samples.\n",
    "    cluster_labels: array\n",
    "        Corresponding non-negative integer cluster labels.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    accuracy: float\n",
    "        fraction of correctly clustered instances.\n",
    "    classes: int array\n",
    "        Assigned class labels sorted in ascending order.\n",
    "    clusters: int array\n",
    "        Cluster labels corresponding to the assigned class labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, class_labels, cluster_labels):\n",
    "        self.class_labels = np.asarray(class_labels)\n",
    "        self.cluster_labels = np.asarray(cluster_labels)\n",
    "        # your python code here\n",
    "        # end of python code\n",
    "        \n",
    "\n",
    "    def __repr__(self):\n",
    "        s = f\"Accuracy: {self.accuracy:.3g}\\n\"\n",
    "        for i, j in np.column_stack((self.classes, self.clusters)):\n",
    "            s += f\"Class #{i} --> Cluster #{j}\\n\"\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ee6b4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37a53dae9ac983f54799135e820f2d00",
     "grade": true,
     "grade_id": "test-c2c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hide-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "# simple case\n",
    "c2c_eval = Classes2ClustersEvaluation(np.array([0, 0, 1, 1]), np.array([0, 1, 2, 2]))\n",
    "assert (c2c_eval.classes == [0, 1]).all()\n",
    "assert (c2c_eval.clusters == [0, 2]).all()\n",
    "assert np.isclose(c2c_eval.accuracy, 0.75, rtol=1e-3)\n",
    "# test on iris\n",
    "c2c_eval = Classes2ClustersEvaluation(dataset[\"target\"], labels)\n",
    "print(c2c_eval)\n",
    "assert np.isclose(c2c_eval.accuracy, 0.96, rtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105181d3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8afb4a875c5e7a2c1dbbcb4177e4ebfb",
     "grade": true,
     "grade_id": "htest-c2c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# hidden tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
